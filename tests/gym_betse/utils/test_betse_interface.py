"""
The following unit test was generated by ChatGPT uses a mock BETSE with toy values, but we ought to do this with
a real BETSE simulation.
"""

import unittest
from gym_betse.utils.betse_interface import BetseSimulation

class TestBetseSimulation(unittest.TestCase):

    def setUp(self):
        # Set up a real BETSE simulation using a test configuration file
        self.sim = BetseSimulation(config_path="test_config.yaml")

    def test_load_simulation(self):
        # Test the load_simulation method to ensure seed and init steps are called
        self.sim.load_simulation()
        self.assertIsNotNone(self.sim.model)  # Ensure the simulation model is initialized

    def test_reset(self):
        # Test the reset method to verify that seed and init steps reset the simulation
        self.sim.reset()
        self.assertIsNotNone(self.sim.model)  # Ensure the simulation model is reset

    def test_apply_action(self):
        # Test apply_action to ensure it updates the YAML config and logs the action
        action = [1.0, 2.0, 3.0]  # Example action parameters
        self.sim.apply_action(action)
        self.assertEqual(self.sim.curr_action, action)  # Check current action is updated
        self.assertIn(action, self.sim.action_log)  # Verify action is logged
        #TODO: Test with a real config file, using the extract_params function in yaml_friend
        #TODO: to verify that the config file is updated correctly.

    def test_step(self):
        # Test the step method to ensure the simulation advances correctly
        self.sim.step()
        self.assertEqual(self.sim.steps_completed, 1)  # Check steps counter increments
        self.assertTrue(self.sim.sim_exists)  # Verify simulation existence flag
        # TODO: We ought to confirm that load_sim creates the conditions seen at the end of the last step,
        # TODO: in terms of the starting state of the simulation being the same as the end state of the last
        # TODO: simulation.

    def test_get_observation(self):
        # TODO: This one is tough to test, since it depends on our goals and architecture. Good luck ig lol
        # Test get_observation to retrieve the simulation's current state
        observation = self.sim.get_observation()
        self.assertIsNotNone(observation)  # Ensure observation is not None
        self.assertTrue(len(observation) > 0)  # Ensure observation contains data

    def test_get_num_actions(self):
        # Test get_num_actions to verify the correct number of actions
        num_actions = self.sim.get_num_actions()
        self.assertEqual(num_actions, 5)  # Example fixed value for the number of actions

    def test_get_observation_shape(self):
        # Test get_observation_shape to ensure it returns the correct shape of the observation
        shape = self.sim.get_observation_shape()
        self.assertIsNotNone(shape)  # Verify the shape is not None
        self.assertTrue(isinstance(shape, int) or isinstance(shape, tuple))  # Verify valid shape format

    def test_is_done(self):
        # Test is_done to verify that the simulation stopping condition is evaluated correctly
        done = self.sim.is_done()
        self.assertFalse(done)  # Example: Always false for this test scenario

    def test_render(self):
        # Test render to ensure plots are displayed or handled properly
        try:
            self.sim.render()
        except Exception as e:
            self.fail(f"Render failed with exception: {e}")

    def test_close(self):
        # Test close to ensure resources are cleaned up correctly
        try:
            self.sim.close()
        except Exception as e:
            self.fail(f"Close failed with exception: {e}")

if __name__ == '__main__':
    unittest.main()
